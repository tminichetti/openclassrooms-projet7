# Air Paradis - Sentiment Analysis API

API de pr√©diction de sentiments pour la d√©tection de bad buzz en temps r√©el.

## üìã Description

Cette API permet d'analyser le sentiment (positif/n√©gatif) de tweets pour aider Air Paradis √† anticiper les probl√®mes de r√©putation et d√©tecter le bad buzz.

**Fonctionnalit√©s principales:**
- ‚úÖ Pr√©diction de sentiment (positif/n√©gatif)
- ‚úÖ Support de plusieurs types de mod√®les (BERT, LSTM, CNN, Logistic Regression)
- ‚úÖ Pr√©diction unitaire et batch
- ‚úÖ API REST avec documentation interactive
- ‚úÖ Monitoring et logging
- ‚úÖ Tests unitaires complets
- ‚úÖ CI/CD avec GitHub Actions
- ‚úÖ D√©ploiement Docker
- ‚úÖ Interface Streamlit pour tests

## üöÄ Installation

### Pr√©requis

- Python 3.9+
- pip
- (Optionnel) Docker

### Installation locale

1. **Cloner le d√©p√¥t:**
```bash
git clone <repository_url>
cd projet7/api
```

2. **Cr√©er un environnement virtuel:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. **Installer les d√©pendances:**
```bash
pip install -r requirements.txt
```

4. **Configurer les variables d'environnement:**
```bash
cp .env.example .env
# √âditer .env avec vos configurations
```

5. **Lancer l'API:**
```bash
python app.py
# ou
uvicorn app:app --host 0.0.0.0 --port 8000 --reload
```

L'API sera accessible √†: http://localhost:8000

## üê≥ Installation avec Docker

### Docker simple

```bash
# Build
docker build -t airparadis-api .

# Run
docker run -p 8000:8000 \
  -e MODEL_TYPE=bert \
  -v $(pwd)/../models:/app/models \
  airparadis-api
```

### Docker Compose (recommand√©)

```bash
# Lancer tous les services (API + Streamlit + MLFlow)
docker-compose up -d

# Voir les logs
docker-compose logs -f

# Arr√™ter
docker-compose down
```

Services disponibles:
- API: http://localhost:8000
- Streamlit: http://localhost:8501
- MLFlow: http://localhost:5001

## üìö Documentation

### Documentation interactive

Une fois l'API lanc√©e, acc√©dez √†:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Endpoints principaux

#### 1. Health Check
```bash
GET /health
```

**R√©ponse:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_type": "bert",
  "timestamp": "2024-01-15T10:30:00"
}
```

#### 2. Pr√©diction simple
```bash
POST /predict
Content-Type: application/json

{
  "text": "This flight was amazing! Best experience ever!"
}
```

**R√©ponse:**
```json
{
  "text": "This flight was amazing! Best experience ever!",
  "sentiment": "1",
  "sentiment_label": "Positif",
  "confidence": 0.92,
  "probabilities": {
    "negative": 0.08,
    "positive": 0.92
  },
  "timestamp": "2024-01-15T10:30:00",
  "model_type": "bert"
}
```

#### 3. Pr√©diction batch
```bash
POST /predict/batch
Content-Type: application/json

{
  "tweets": [
    "Great service!",
    "Terrible experience",
    "Amazing quality!"
  ]
}
```

**R√©ponse:**
```json
{
  "predictions": [...],
  "count": 3,
  "model_type": "bert",
  "timestamp": "2024-01-15T10:30:00"
}
```

#### 4. Informations sur les mod√®les
```bash
GET /models
```

### Exemples avec curl

```bash
# Health check
curl http://localhost:8000/health

# Pr√©diction simple
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "Great flight experience!"}'

# Pr√©diction batch
curl -X POST "http://localhost:8000/predict/batch" \
  -H "Content-Type: application/json" \
  -d '{"tweets": ["Great!", "Bad!", "Okay"]}'
```

### Exemples avec Python

```python
import requests

# Pr√©diction simple
response = requests.post(
    "http://localhost:8000/predict",
    json={"text": "This is amazing!"}
)
result = response.json()
print(f"Sentiment: {result['sentiment_label']}")
print(f"Confiance: {result['confidence']:.1%}")

# Pr√©diction batch
response = requests.post(
    "http://localhost:8000/predict/batch",
    json={"tweets": ["Great!", "Bad!", "Okay"]}
)
results = response.json()
print(f"Analys√© {results['count']} tweets")
```

## üß™ Tests

### Ex√©cuter les tests

```bash
# Tests simples
pytest test_api.py -v

# Tests avec couverture
pytest test_api.py -v --cov=app --cov-report=html

# Tests sp√©cifiques
pytest test_api.py::TestPredictEndpoint -v
```

### Rapport de couverture

Apr√®s avoir ex√©cut√© les tests avec couverture, ouvrez `htmlcov/index.html` dans votre navigateur.

## üé® Interface Streamlit

### Lancer l'interface

```bash
streamlit run streamlit_app.py
```

Acc√©dez √†: http://localhost:8501

**Fonctionnalit√©s:**
- Analyse de tweets unitaires
- Analyse batch (fichier CSV ou texte)
- Visualisations interactives
- Export des r√©sultats

## üìä Monitoring avec MLFlow

### Lancer MLFlow

```bash
mlflow ui --port 5001
```

Acc√©dez √†: http://localhost:5001

Vous pourrez voir:
- Toutes les exp√©riences d'entra√Ænement
- M√©triques (accuracy, F1, etc.)
- Param√®tres des mod√®les
- Artefacts sauvegard√©s

## üîß Configuration

### Variables d'environnement

Cr√©ez un fichier `.env` bas√© sur `.env.example`:

```bash
MODEL_TYPE=bert           # Type de mod√®le (bert, lstm, cnn, logistic)
MODEL_PATH=../models/...  # Chemin vers le mod√®le
PORT=8000                 # Port de l'API
WORKERS=2                 # Nombre de workers
```

### Changer de mod√®le

Pour utiliser un mod√®le diff√©rent:

```bash
# Via variable d'environnement
export MODEL_TYPE=lstm
export MODEL_PATH=../models/lstm_model.h5

# Via Docker
docker run -e MODEL_TYPE=bert -e MODEL_PATH=/app/models/bert airparadis-api
```

## üö¢ D√©ploiement

### Heroku

```bash
# Login
heroku login

# Cr√©er l'application
heroku create airparadis-api

# Configurer les variables
heroku config:set MODEL_TYPE=bert

# D√©ployer
git push heroku main
```

### Azure

```bash
# Login Azure
az login

# Cr√©er le groupe de ressources
az group create --name airparadis-rg --location westeurope

# D√©ployer le container
az container create \
  --resource-group airparadis-rg \
  --name airparadis-api \
  --image <your-docker-image> \
  --ports 8000 \
  --environment-variables MODEL_TYPE=bert
```

### GitHub Actions (CI/CD)

Le pipeline CI/CD est configur√© dans `.github/workflows/ci-cd.yml`.

**D√©clencheurs:**
- Push sur main/master
- Pull requests
- Workflow manuel

**√âtapes:**
1. Tests et linting
2. Build Docker image
3. Scan de s√©curit√©
4. D√©ploiement Heroku/Azure
5. Tests de smoke

**Secrets requis:**
- `HEROKU_API_KEY`
- `HEROKU_APP_NAME`
- `HEROKU_EMAIL`
- `AZURE_CREDENTIALS` (optionnel)

## üìà Performance

### Latence

- Pr√©diction simple: ~100-300ms (BERT), ~10-50ms (Logistic)
- Pr√©diction batch (10 tweets): ~500-1000ms (BERT)

### Limites

- Texte maximum: 280 caract√®res
- Batch maximum: 100 tweets
- Rate limit: 100 requ√™tes/minute (configurable)

## üõ°Ô∏è S√©curit√©

- ‚úÖ Validation des entr√©es avec Pydantic
- ‚úÖ Sanitization des donn√©es
- ‚úÖ CORS configur√©
- ‚úÖ Scan de s√©curit√© automatique (Trivy, Safety)
- ‚úÖ Container non-root
- ‚úÖ Health checks

## ü§ù Contribution

### D√©veloppement

```bash
# Installer les d√©pendances de dev
pip install -r requirements-dev.txt

# Formatter le code
black app.py

# Linter
flake8 app.py
pylint app.py

# Tests
pytest -v
```

### Pre-commit hooks

```bash
pre-commit install
```

## üìù TODO

- [ ] Ajouter l'authentification (JWT)
- [ ] Impl√©menter le rate limiting
- [ ] Ajouter le caching Redis
- [ ] Am√©liorer le monitoring
- [ ] Cr√©er des dashboards Azure Insights

## üìÑ Licence

Ce projet est d√©velopp√© dans le cadre du Projet 7 d'OpenClassrooms.

## üë§ Auteur

**Thomas** - OpenClassrooms Data Science Master

## üôè Remerciements

- OpenClassrooms
- Air Paradis (client fictif)
- Hugging Face (mod√®les BERT)
- FastAPI, Streamlit, MLFlow

## üìû Contact

Pour toute question:
- GitHub Issues: [Cr√©er une issue](https://github.com/...)
- Email: contact@example.com

---

Made with ‚ù§Ô∏è for OpenClassrooms Projet 7
