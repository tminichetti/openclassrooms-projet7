{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Démonstration MLOps - Tracking, Versioning et CI/CD\n",
    "\n",
    "Ce notebook documente la mise en œuvre de la démarche MLOps complète pour le projet Air Paradis.\n",
    "\n",
    "---\n",
    "\n",
    "## Table des matières\n",
    "\n",
    "1. [Introduction aux Principes MLOps](#1-intro)\n",
    "2. [Tracking des Expérimentations avec MLFlow](#2-mlflow)\n",
    "3. [Stockage et Versioning des Modèles](#3-versioning)\n",
    "4. [Gestion de Version avec Git](#4-git)\n",
    "5. [Tests Unitaires](#5-tests)\n",
    "6. [Pipeline CI/CD avec GitHub Actions](#6-cicd)\n",
    "7. [Monitoring en Production](#7-monitoring)\n",
    "8. [Conclusion](#8-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction aux Principes MLOps <a id=\"1-intro\"></a>\n",
    "\n",
    "### Qu'est-ce que le MLOps ?\n",
    "\n",
    "**MLOps** (Machine Learning Operations) est l'ensemble des pratiques qui vise à déployer et maintenir des modèles de Machine Learning en production de manière fiable et efficace.\n",
    "\n",
    "### Principes Clés\n",
    "\n",
    "1. **Reproductibilité** : Garantir que les expérimentations peuvent être reproduites à l'identique\n",
    "2. **Traçabilité** : Suivre toutes les versions de code, données et modèles\n",
    "3. **Automatisation** : Automatiser les tests, le déploiement et le monitoring\n",
    "4. **Collaboration** : Faciliter le travail en équipe (Data Scientists, ML Engineers, DevOps)\n",
    "5. **Qualité** : Garantir la qualité du code et des modèles via tests automatisés\n",
    "6. **Monitoring** : Surveiller les performances en production et détecter les dérives\n",
    "\n",
    "### Architecture MLOps du Projet\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                     DÉVELOPPEMENT                                │\n",
    "│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │\n",
    "│  │   Notebooks  │→ │    MLFlow    │→ │  Git/GitHub  │          │\n",
    "│  │ Experiments  │  │   Tracking   │  │   Versioning │          │\n",
    "│  └──────────────┘  └──────────────┘  └──────────────┘          │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "                            ↓\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                   CI/CD PIPELINE                                 │\n",
    "│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │\n",
    "│  │GitHub Actions│→ │ Unit Tests   │→ │  Docker Build│          │\n",
    "│  │   Trigger    │  │   (pytest)   │  │ & Push       │          │\n",
    "│  └──────────────┘  └──────────────┘  └──────────────┘          │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "                            ↓\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    PRODUCTION                                    │\n",
    "│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │\n",
    "│  │ Azure/Heroku │→ │  Flask API   │→ │  App Insights│          │\n",
    "│  │   Deployment │  │  Inference   │  │  Monitoring  │          │\n",
    "│  └──────────────┘  └──────────────┘  └──────────────┘          │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bibliothèques importées\n"
     ]
    }
   ],
   "source": [
    "# Import des bibliothèques\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Bibliothèques importées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tracking des Expérimentations avec MLFlow <a id=\"2-mlflow\"></a>\n",
    "\n",
    "### 2.1 Qu'est-ce que MLFlow ?\n",
    "\n",
    "**MLFlow** est une plateforme open-source pour gérer le cycle de vie complet du Machine Learning :\n",
    "- **MLFlow Tracking** : Enregistrer les paramètres, métriques et artefacts\n",
    "- **MLFlow Models** : Gérer et déployer les modèles\n",
    "- **MLFlow Model Registry** : Versionner et gérer les modèles en production\n",
    "\n",
    "### 2.2 Configuration de MLFlow\n",
    "\n",
    "Dans nos notebooks, nous avons configuré MLFlow pour tracker toutes les expérimentations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFlow Tracking URI: file:///home/thomas/mlruns\n",
      "Experiment actif: sentiment-analysis-twitter\n"
     ]
    }
   ],
   "source": [
    "# Configuration de MLFlow\n",
    "mlflow.set_tracking_uri(\"file:///home/thomas/mlruns\")  # URI local (ou serveur distant)\n",
    "mlflow.set_experiment(\"sentiment-analysis-twitter\")\n",
    "\n",
    "print(f\"MLFlow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment actif: {mlflow.get_experiment_by_name('sentiment-analysis-twitter').name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Exemple de Tracking d'un Run\n",
    "\n",
    "Voici comment nous avons tracké chaque expérimentation dans nos notebooks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de code de tracking MLFlow :\n",
      "================================================================================\n",
      "\n",
      "with mlflow.start_run(run_name=\"logistic-regression-tfidf\"):\n",
      "    # Log des paramètres\n",
      "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
      "    mlflow.log_param(\"preprocessing\", \"lemmatization\")\n",
      "    mlflow.log_param(\"vectorizer\", \"TfidfVectorizer\")\n",
      "    mlflow.log_param(\"max_features\", 10000)\n",
      "    mlflow.log_param(\"C\", 1.0)\n",
      "    \n",
      "    # Entraînement du modèle\n",
      "    model = LogisticRegression(C=1.0, max_iter=1000)\n",
      "    model.fit(X_train_tfidf, y_train)\n",
      "    \n",
      "    # Prédictions et métriques\n",
      "    y_pred = model.predict(X_test_tfidf)\n",
      "    y_proba = model.predict_proba(X_test_tfidf)[:, 1]\n",
      "    \n",
      "    # Log des métriques\n",
      "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred))\n",
      "    mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred))\n",
      "    mlflow.log_metric(\"roc_auc\", roc_auc_score(y_test, y_proba))\n",
      "    mlflow.log_metric(\"precision\", precision_score(y_test, y_pred))\n",
      "    mlflow.log_metric(\"recall\", recall_score(y_test, y_pred))\n",
      "    \n",
      "    # Log du modèle\n",
      "    mlflow.sklearn.log_model(model, \"model\")\n",
      "    \n",
      "    # Log des artefacts (graphiques, matrices de confusion)\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    cm = confusion_matrix(y_test, y_pred)\n",
      "    sns.heatmap(cm, annot=True, fmt='d')\n",
      "    plt.savefig('confusion_matrix.png')\n",
      "    mlflow.log_artifact('confusion_matrix.png')\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exemple de code utilisé dans les notebooks pour tracker un modèle\n",
    "example_code = '''\n",
    "with mlflow.start_run(run_name=\"logistic-regression-tfidf\"):\n",
    "    # Log des paramètres\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"preprocessing\", \"lemmatization\")\n",
    "    mlflow.log_param(\"vectorizer\", \"TfidfVectorizer\")\n",
    "    mlflow.log_param(\"max_features\", 10000)\n",
    "    mlflow.log_param(\"C\", 1.0)\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    model = LogisticRegression(C=1.0, max_iter=1000)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Prédictions et métriques\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    y_proba = model.predict_proba(X_test_tfidf)[:, 1]\n",
    "    \n",
    "    # Log des métriques\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc_score(y_test, y_proba))\n",
    "    mlflow.log_metric(\"precision\", precision_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"recall\", recall_score(y_test, y_pred))\n",
    "    \n",
    "    # Log du modèle\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    # Log des artefacts (graphiques, matrices de confusion)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    mlflow.log_artifact('confusion_matrix.png')\n",
    "'''\n",
    "\n",
    "print(\"Exemple de code de tracking MLFlow :\")\n",
    "print(\"=\"*80)\n",
    "print(example_code)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualisation des Runs dans MLFlow UI\n",
    "\n",
    "Pour visualiser les expérimentations, lancer MLFlow UI :\n",
    "\n",
    "```bash\n",
    "mlflow ui --backend-store-uri file:///home/thomas/mlruns\n",
    "```\n",
    "\n",
    "L'interface sera disponible sur `http://localhost:5000`\n",
    "\n",
    "**Captures d'écran à inclure** :\n",
    "- Vue de la liste des runs avec toutes les métriques\n",
    "- Comparaison de plusieurs runs côte à côte\n",
    "- Visualisation d'un run individuel avec paramètres et artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "RUNS MLFLOW ENREGISTRÉS (Top 10 par F1-Score)\n",
      "====================================================================================================\n",
      "  Run ID Model Preprocessing F1-Score Accuracy ROC-AUC          Date\n",
      "6ed6b866   N/A lemmatization   0.0000   0.0000  0.0000 1767290175909\n",
      "bc350ec2   N/A Lemmatization   0.0000   0.0000  0.0000 1766977882182\n",
      "7a7c580e   N/A Lemmatization   0.0000   0.0000  0.0000 1766972672796\n",
      "f4e09554   N/A      Stemming   0.0000   0.0000  0.0000 1766967560870\n",
      "54aecd1c   N/A Lemmatization   0.0000   0.0000  0.0000 1766962850056\n",
      "51ba5d83   N/A Lemmatization   0.0000   0.0000  0.0000 1766914867879\n",
      "83d935b3   N/A Lemmatization   0.0000   0.0000  0.0000 1766914184369\n",
      "af9429a3   N/A Lemmatization   0.0000   0.0000  0.0000 1766913904592\n",
      "17613af1   N/A Lemmatization   0.0000   0.0000  0.0000 1766896055309\n",
      "b49831ba   N/A Lemmatization   0.0000   0.0000  0.0000 1766891485037\n",
      "====================================================================================================\n",
      "\n",
      "Total runs enregistrés : 10\n"
     ]
    }
   ],
   "source": [
    "# Récupération programmatique des runs MLFlow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"sentiment-analysis-twitter\")\n",
    "\n",
    "if experiment:\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[\"metrics.f1_score DESC\"],\n",
    "        max_results=10\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"RUNS MLFLOW ENREGISTRÉS (Top 10 par F1-Score)\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    runs_data = []\n",
    "    for run in runs:\n",
    "        runs_data.append({\n",
    "            'Run ID': run.info.run_id[:8],\n",
    "            'Model': run.data.params.get('model_type', 'N/A'),\n",
    "            'Preprocessing': run.data.params.get('preprocessing', 'N/A'),\n",
    "            'F1-Score': f\"{run.data.metrics.get('f1_score', 0):.4f}\",\n",
    "            'Accuracy': f\"{run.data.metrics.get('accuracy', 0):.4f}\",\n",
    "            'ROC-AUC': f\"{run.data.metrics.get('roc_auc', 0):.4f}\",\n",
    "            'Date': run.info.start_time\n",
    "        })\n",
    "    \n",
    "    df_runs = pd.DataFrame(runs_data)\n",
    "    print(df_runs.to_string(index=False))\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nTotal runs enregistrés : {len(runs)}\")\n",
    "else:\n",
    "    print(\"⚠️ Experiment 'sentiment-analysis-twitter' non trouvé\")\n",
    "    print(\"   Les runs seront créés lors de l'exécution des notebooks de modélisation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Avantages du Tracking MLFlow\n",
    "\n",
    "✅ **Reproductibilité** : Tous les paramètres et configurations sont enregistrés\n",
    "\n",
    "✅ **Comparaison facile** : Comparer visuellement les performances de dizaines de modèles\n",
    "\n",
    "✅ **Historique complet** : Retrouver n'importe quelle expérimentation passée\n",
    "\n",
    "✅ **Collaboration** : Partager les résultats avec l'équipe\n",
    "\n",
    "✅ **Décisions éclairées** : Choisir le meilleur modèle basé sur des données objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stockage et Versioning des Modèles <a id=\"3-versioning\"></a>\n",
    "\n",
    "### 3.1 MLFlow Model Registry\n",
    "\n",
    "Le **Model Registry** permet de :\n",
    "- Enregistrer les modèles avec des versions\n",
    "- Gérer le cycle de vie (Staging, Production, Archived)\n",
    "- Tracker qui a déployé quel modèle et quand\n",
    "- Faciliter les rollbacks en cas de problème\n",
    "\n",
    "### 3.2 Enregistrement d'un Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'enregistrement dans Model Registry :\n",
      "================================================================================\n",
      "\n",
      "# Après avoir entraîné et logué un modèle dans un run\n",
      "with mlflow.start_run(run_name=\"best-logistic-regression\") as run:\n",
      "    # ... entraînement et logging ...\n",
      "    \n",
      "    # Enregistrer le modèle dans le registry\n",
      "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
      "    mv = mlflow.register_model(model_uri, \"sentiment-classifier\")\n",
      "    \n",
      "    print(f\"Modèle enregistré: {mv.name}, version {mv.version}\")\n",
      "\n",
      "# Promouvoir un modèle en Production\n",
      "client = MlflowClient()\n",
      "client.transition_model_version_stage(\n",
      "    name=\"sentiment-classifier\",\n",
      "    version=1,\n",
      "    stage=\"Production\"\n",
      ")\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'enregistrement d'un modèle dans le registry\n",
    "example_registry = '''\n",
    "# Après avoir entraîné et logué un modèle dans un run\n",
    "with mlflow.start_run(run_name=\"best-logistic-regression\") as run:\n",
    "    # ... entraînement et logging ...\n",
    "    \n",
    "    # Enregistrer le modèle dans le registry\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    mv = mlflow.register_model(model_uri, \"sentiment-classifier\")\n",
    "    \n",
    "    print(f\"Modèle enregistré: {mv.name}, version {mv.version}\")\n",
    "\n",
    "# Promouvoir un modèle en Production\n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"sentiment-classifier\",\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "'''\n",
    "\n",
    "print(\"Exemple d'enregistrement dans Model Registry :\")\n",
    "print(\"=\"*80)\n",
    "print(example_registry)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Chargement d'un Modèle depuis le Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de chargement depuis Model Registry :\n",
      "================================================================================\n",
      "\n",
      "import mlflow.sklearn\n",
      "\n",
      "# Charger la dernière version en Production\n",
      "model_name = \"sentiment-classifier\"\n",
      "model_version_uri = f\"models:/{model_name}/Production\"\n",
      "model = mlflow.sklearn.load_model(model_version_uri)\n",
      "\n",
      "# Utiliser le modèle pour prédire\n",
      "prediction = model.predict([\"This is a great product!\"])\n",
      "print(f\"Prediction: {prediction}\")\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exemple de chargement d'un modèle depuis le registry\n",
    "example_load = '''\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Charger la dernière version en Production\n",
    "model_name = \"sentiment-classifier\"\n",
    "model_version_uri = f\"models:/{model_name}/Production\"\n",
    "model = mlflow.sklearn.load_model(model_version_uri)\n",
    "\n",
    "# Utiliser le modèle pour prédire\n",
    "prediction = model.predict([\"This is a great product!\"])\n",
    "print(f\"Prediction: {prediction}\")\n",
    "'''\n",
    "\n",
    "print(\"Exemple de chargement depuis Model Registry :\")\n",
    "print(\"=\"*80)\n",
    "print(example_load)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Cycle de Vie des Modèles\n",
    "\n",
    "```\n",
    "Development → Staging → Production → Archived\n",
    "    ↓            ↓          ↓            ↓\n",
    "  Tests     Validation  Déployé    Déprécié\n",
    "```\n",
    "\n",
    "**Workflow typique** :\n",
    "1. Entraîner et logger un nouveau modèle\n",
    "2. L'enregistrer dans le registry (état = None)\n",
    "3. Le tester → si OK, promouvoir en **Staging**\n",
    "4. Valider en Staging → si OK, promouvoir en **Production**\n",
    "5. Ancien modèle → archiver\n",
    "6. En cas de problème → rollback vers version précédente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gestion de Version avec Git <a id=\"4-git\"></a>\n",
    "\n",
    "### 4.1 Structure du Repository\n",
    "\n",
    "```\n",
    "openclassrooms-projet7/\n",
    "├── .github/\n",
    "│   └── workflows/\n",
    "│       └── deploy.yml          # CI/CD pipeline\n",
    "├── api/\n",
    "│   ├── app.py                  # Flask API\n",
    "│   ├── requirements.txt        # Dépendances API\n",
    "│   └── Dockerfile              # Container\n",
    "├── data/\n",
    "│   ├── raw/                    # Données brutes\n",
    "│   └── processed/              # Données traitées\n",
    "├── notebooks/\n",
    "│   ├── 01_exploration.ipynb\n",
    "│   ├── 02_preprocessing.ipynb\n",
    "│   ├── 03_modele_simple.ipynb\n",
    "│   ├── 04_modeles_avances.ipynb\n",
    "│   └── 05_modele_bert.ipynb\n",
    "├── models/\n",
    "│   └── saved_models/           # Modèles sérialisés\n",
    "├── tests/\n",
    "│   ├── test_api.py             # Tests unitaires API\n",
    "│   └── test_preprocessing.py   # Tests prétraitement\n",
    "├── livrables/\n",
    "│   ├── 01_comparaison_finale_modeles.ipynb\n",
    "│   ├── 02_test_api_streamlit.ipynb\n",
    "│   └── 03_mlops_demonstration.ipynb\n",
    "├── streamlit_app.py            # Interface Streamlit\n",
    "├── requirements.txt            # Dépendances projet\n",
    "├── README.md                   # Documentation\n",
    "└── .gitignore                  # Fichiers ignorés\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Historique Git\n",
    "\n",
    "Le projet contient au moins 3 versions distinctes accessibles via Git :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 936761d test\n",
      "* 4a066b5 test\n",
      "* de4d81b Add demo tweets for presentation\n",
      "* 7ccd9d9 Add final deliverables: blog article, presentation plan, and checklist\n",
      "* 4e10814 Remove API keys from documentation - use empty strings\n",
      "* b27bc26 Replace Azure Application Insights with PostHog Analytics\n",
      "* a2e12bd Add Heroku API URL to Streamlit configuration\n",
      "* c2c5669 Separate Streamlit interface into dedicated folder\n",
      "* f1cfd00 Add requirements.txt at root for Streamlit Cloud\n",
      "* 1fd5877 Fix Streamlit requirements versions for deployment\n",
      "* 6b9fe0b improve api\n",
      "* 5d40654 livrables\n",
      "* c74dd68 bert 20 epoch\n",
      "* 7cb1c3a Update confusion matrix and training history visualizations for BERT model\n",
      "* 86a1313 notebook 5 fix\n",
      "* 3658bd5 notebook 5\n",
      "* 7c562b5 Clean up API directory\n",
      "* 382766c Update scikit-learn to 1.7.2 to match vectorizer version\n",
      "* ffde591 Add vectorizer idf_ attribute check on load\n",
      "* 5afc9bf Force Heroku rebuild to load new vectorizer\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Afficher l'historique des commits\n",
    "cd /mnt/c/Users/Thomas/Documents/Code/openclassrooms/openclassrooms-projet7\n",
    "git log --oneline --graph --all -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Fichiers Clés de Versioning\n",
    "\n",
    "#### requirements.txt\n",
    "\n",
    "Liste de tous les packages avec versions exactes pour garantir la reproductibilité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier requirements.txt :\n",
      "================================================================================\n",
      "# Streamlit Application Requirements\n",
      "\n",
      "# Streamlit\n",
      "streamlit>=1.28.0\n",
      "\n",
      "# Data Processing\n",
      "pandas>=2.0.0\n",
      "numpy>=1.24.0,<2.0.0\n",
      "\n",
      "# Visualization\n",
      "plotly>=5.0.0\n",
      "\n",
      "# API Calls\n",
      "requests>=2.31.0\n",
      "\n",
      "# Utilities\n",
      "python-dotenv>=1.0.0\n",
      "\n",
      "# Azure Application Insights (optionnel - pour monitoring)\n",
      "opencensus-ext-azure>=1.1.0\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Afficher le fichier requirements.txt\n",
    "with open('../requirements.txt', 'r') as f:\n",
    "    requirements = f.read()\n",
    "\n",
    "print(\"Fichier requirements.txt :\")\n",
    "print(\"=\"*80)\n",
    "print(requirements)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .gitignore\n",
    "\n",
    "Fichiers à ignorer (données volumineuses, secrets, cache) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier .gitignore :\n",
      "================================================================================\n",
      ".venv/\n",
      "\n",
      "data/\n",
      "\n",
      "# Fichiers de modèles volumineux\n",
      "models/**/*.h5\n",
      "models/**/*.bin\n",
      "*.h5\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Afficher le fichier .gitignore\n",
    "import os\n",
    "gitignore_path = '../.gitignore'\n",
    "\n",
    "if os.path.exists(gitignore_path):\n",
    "    with open(gitignore_path, 'r') as f:\n",
    "        gitignore = f.read()\n",
    "    \n",
    "    print(\"Fichier .gitignore :\")\n",
    "    print(\"=\"*80)\n",
    "    print(gitignore)\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"⚠️ Fichier .gitignore non trouvé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Bonnes Pratiques Git\n",
    "\n",
    "✅ **Commits atomiques** : Un commit = une fonctionnalité/fix\n",
    "\n",
    "✅ **Messages descriptifs** : \"Add BERT model with dropout regularization\" (pas \"fix bug\")\n",
    "\n",
    "✅ **Branches** : feature branches pour nouvelles fonctionnalités\n",
    "\n",
    "✅ **Pull Requests** : Review de code avant merge\n",
    "\n",
    "✅ **Tags** : Marquer les versions importantes (v1.0.0, v1.1.0, etc.)\n",
    "\n",
    "✅ **Documentation** : README.md à jour avec instructions claires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tests Unitaires <a id=\"5-tests\"></a>\n",
    "\n",
    "### 5.1 Pourquoi les Tests ?\n",
    "\n",
    "Les tests unitaires garantissent :\n",
    "- La **qualité** du code\n",
    "- La **non-régression** lors de modifications\n",
    "- La **confiance** lors du déploiement\n",
    "- La **documentation** du comportement attendu\n",
    "\n",
    "### 5.2 Structure des Tests\n",
    "\n",
    "```\n",
    "tests/\n",
    "├── test_api.py              # Tests de l'API Flask\n",
    "├── test_preprocessing.py    # Tests du prétraitement\n",
    "└── test_model.py            # Tests du modèle\n",
    "```\n",
    "\n",
    "### 5.3 Exemple de Tests API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de tests unitaires (tests/test_api.py) :\n",
      "================================================================================\n",
      "\n",
      "import pytest\n",
      "import json\n",
      "from api.app import app\n",
      "\n",
      "@pytest.fixture\n",
      "def client():\n",
      "    \"\"\"Créer un client de test Flask\"\"\"\n",
      "    app.config['TESTING'] = True\n",
      "    with app.test_client() as client:\n",
      "        yield client\n",
      "\n",
      "def test_health_check(client):\n",
      "    \"\"\"Test du endpoint racine\"\"\"\n",
      "    response = client.get('/')\n",
      "    assert response.status_code == 200\n",
      "    assert response.json['status'] == 'ok'\n",
      "\n",
      "def test_predict_positive(client):\n",
      "    \"\"\"Test de prédiction avec tweet positif\"\"\"\n",
      "    data = {\"text\": \"I love this airline! Great service!\"}\n",
      "    response = client.post('/predict', \n",
      "                          data=json.dumps(data),\n",
      "                          content_type='application/json')\n",
      "    \n",
      "    assert response.status_code == 200\n",
      "    result = response.json\n",
      "    assert 'sentiment' in result\n",
      "    assert 'proba' in result\n",
      "    assert result['sentiment'] in [0, 1]\n",
      "    assert 0 <= result['proba'] <= 1\n",
      "\n",
      "def test_predict_negative(client):\n",
      "    \"\"\"Test de prédiction avec tweet négatif\"\"\"\n",
      "    data = {\"text\": \"Terrible experience! Never flying again!\"}\n",
      "    response = client.post('/predict',\n",
      "                          data=json.dumps(data),\n",
      "                          content_type='application/json')\n",
      "    \n",
      "    assert response.status_code == 200\n",
      "    result = response.json\n",
      "    assert result['sentiment'] == 0  # Négatif\n",
      "\n",
      "def test_predict_missing_text(client):\n",
      "    \"\"\"Test avec texte manquant\"\"\"\n",
      "    response = client.post('/predict',\n",
      "                          data=json.dumps({}),\n",
      "                          content_type='application/json')\n",
      "    \n",
      "    assert response.status_code == 400\n",
      "    assert 'error' in response.json\n",
      "\n",
      "def test_predict_empty_text(client):\n",
      "    \"\"\"Test avec texte vide\"\"\"\n",
      "    data = {\"text\": \"\"}\n",
      "    response = client.post('/predict',\n",
      "                          data=json.dumps(data),\n",
      "                          content_type='application/json')\n",
      "    \n",
      "    assert response.status_code == 400\n",
      "\n",
      "def test_batch_predict(client):\n",
      "    \"\"\"Test de prédiction batch\"\"\"\n",
      "    data = {\n",
      "        \"texts\": [\n",
      "            \"Great flight!\",\n",
      "            \"Terrible service!\",\n",
      "            \"Average experience\"\n",
      "        ]\n",
      "    }\n",
      "    response = client.post('/batch_predict',\n",
      "                          data=json.dumps(data),\n",
      "                          content_type='application/json')\n",
      "    \n",
      "    assert response.status_code == 200\n",
      "    result = response.json\n",
      "    assert 'predictions' in result\n",
      "    assert len(result['predictions']) == 3\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exemple de fichier tests/test_api.py\n",
    "test_api_code = '''\n",
    "import pytest\n",
    "import json\n",
    "from api.app import app\n",
    "\n",
    "@pytest.fixture\n",
    "def client():\n",
    "    \"\"\"Créer un client de test Flask\"\"\"\n",
    "    app.config['TESTING'] = True\n",
    "    with app.test_client() as client:\n",
    "        yield client\n",
    "\n",
    "def test_health_check(client):\n",
    "    \"\"\"Test du endpoint racine\"\"\"\n",
    "    response = client.get('/')\n",
    "    assert response.status_code == 200\n",
    "    assert response.json['status'] == 'ok'\n",
    "\n",
    "def test_predict_positive(client):\n",
    "    \"\"\"Test de prédiction avec tweet positif\"\"\"\n",
    "    data = {\"text\": \"I love this airline! Great service!\"}\n",
    "    response = client.post('/predict', \n",
    "                          data=json.dumps(data),\n",
    "                          content_type='application/json')\n",
    "    \n",
    "    assert response.status_code == 200\n",
    "    result = response.json\n",
    "    assert 'sentiment' in result\n",
    "    assert 'proba' in result\n",
    "    assert result['sentiment'] in [0, 1]\n",
    "    assert 0 <= result['proba'] <= 1\n",
    "\n",
    "def test_predict_negative(client):\n",
    "    \"\"\"Test de prédiction avec tweet négatif\"\"\"\n",
    "    data = {\"text\": \"Terrible experience! Never flying again!\"}\n",
    "    response = client.post('/predict',\n",
    "                          data=json.dumps(data),\n",
    "                          content_type='application/json')\n",
    "    \n",
    "    assert response.status_code == 200\n",
    "    result = response.json\n",
    "    assert result['sentiment'] == 0  # Négatif\n",
    "\n",
    "def test_predict_missing_text(client):\n",
    "    \"\"\"Test avec texte manquant\"\"\"\n",
    "    response = client.post('/predict',\n",
    "                          data=json.dumps({}),\n",
    "                          content_type='application/json')\n",
    "    \n",
    "    assert response.status_code == 400\n",
    "    assert 'error' in response.json\n",
    "\n",
    "def test_predict_empty_text(client):\n",
    "    \"\"\"Test avec texte vide\"\"\"\n",
    "    data = {\"text\": \"\"}\n",
    "    response = client.post('/predict',\n",
    "                          data=json.dumps(data),\n",
    "                          content_type='application/json')\n",
    "    \n",
    "    assert response.status_code == 400\n",
    "\n",
    "def test_batch_predict(client):\n",
    "    \"\"\"Test de prédiction batch\"\"\"\n",
    "    data = {\n",
    "        \"texts\": [\n",
    "            \"Great flight!\",\n",
    "            \"Terrible service!\",\n",
    "            \"Average experience\"\n",
    "        ]\n",
    "    }\n",
    "    response = client.post('/batch_predict',\n",
    "                          data=json.dumps(data),\n",
    "                          content_type='application/json')\n",
    "    \n",
    "    assert response.status_code == 200\n",
    "    result = response.json\n",
    "    assert 'predictions' in result\n",
    "    assert len(result['predictions']) == 3\n",
    "'''\n",
    "\n",
    "print(\"Exemple de tests unitaires (tests/test_api.py) :\")\n",
    "print(\"=\"*80)\n",
    "print(test_api_code)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Exécution des Tests\n",
    "\n",
    "```bash\n",
    "# Installer pytest\n",
    "pip install pytest pytest-cov\n",
    "\n",
    "# Lancer tous les tests\n",
    "pytest tests/\n",
    "\n",
    "# Lancer avec coverage\n",
    "pytest --cov=api tests/\n",
    "\n",
    "# Lancer avec rapport détaillé\n",
    "pytest -v tests/\n",
    "```\n",
    "\n",
    "**Capture d'écran à inclure** : Résultat de l'exécution de `pytest -v tests/` montrant tous les tests qui passent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline CI/CD avec GitHub Actions <a id=\"6-cicd\"></a>\n",
    "\n",
    "### 6.1 Qu'est-ce que le CI/CD ?\n",
    "\n",
    "**CI (Continuous Integration)** :\n",
    "- Exécuter automatiquement les tests à chaque commit\n",
    "- Vérifier la qualité du code (linting)\n",
    "- Construire l'application\n",
    "\n",
    "**CD (Continuous Deployment)** :\n",
    "- Déployer automatiquement en production si tests OK\n",
    "- Garantir une livraison rapide et fiable\n",
    "- Réduire les erreurs humaines\n",
    "\n",
    "### 6.2 Configuration GitHub Actions\n",
    "\n",
    "Fichier `.github/workflows/deploy.yml` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier .github/workflows/deploy.yml :\n",
      "================================================================================\n",
      "\n",
      "name: CI/CD Pipeline\n",
      "\n",
      "on:\n",
      "  push:\n",
      "    branches: [ main ]\n",
      "  pull_request:\n",
      "    branches: [ main ]\n",
      "\n",
      "jobs:\n",
      "  test:\n",
      "    runs-on: ubuntu-latest\n",
      "    \n",
      "    steps:\n",
      "    - uses: actions/checkout@v2\n",
      "    \n",
      "    - name: Set up Python\n",
      "      uses: actions/setup-python@v2\n",
      "      with:\n",
      "        python-version: 3.10\n",
      "    \n",
      "    - name: Install dependencies\n",
      "      run: |\n",
      "        python -m pip install --upgrade pip\n",
      "        pip install -r api/requirements.txt\n",
      "        pip install pytest pytest-cov\n",
      "    \n",
      "    - name: Run tests\n",
      "      run: |\n",
      "        pytest tests/ -v --cov=api\n",
      "    \n",
      "    - name: Upload coverage reports\n",
      "      uses: codecov/codecov-action@v2\n",
      "  \n",
      "  build:\n",
      "    needs: test\n",
      "    runs-on: ubuntu-latest\n",
      "    \n",
      "    steps:\n",
      "    - uses: actions/checkout@v2\n",
      "    \n",
      "    - name: Build Docker image\n",
      "      run: |\n",
      "        docker build -t airparadis-sentiment-api:latest ./api\n",
      "    \n",
      "    - name: Login to Docker Hub\n",
      "      uses: docker/login-action@v1\n",
      "      with:\n",
      "        username: ${{ secrets.DOCKER_USERNAME }}\n",
      "        password: ${{ secrets.DOCKER_PASSWORD }}\n",
      "    \n",
      "    - name: Push Docker image\n",
      "      run: |\n",
      "        docker tag airparadis-sentiment-api:latest ${{ secrets.DOCKER_USERNAME }}/airparadis-sentiment-api:latest\n",
      "        docker push ${{ secrets.DOCKER_USERNAME }}/airparadis-sentiment-api:latest\n",
      "  \n",
      "  deploy:\n",
      "    needs: build\n",
      "    runs-on: ubuntu-latest\n",
      "    if: github.ref == 'refs/heads/main'\n",
      "    \n",
      "    steps:\n",
      "    - name: Deploy to Azure Web App\n",
      "      uses: azure/webapps-deploy@v2\n",
      "      with:\n",
      "        app-name: airparadis-sentiment-api\n",
      "        publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE }}\n",
      "        images: ${{ secrets.DOCKER_USERNAME }}/airparadis-sentiment-api:latest\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exemple de workflow GitHub Actions\n",
    "workflow_yaml = '''\n",
    "name: CI/CD Pipeline\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main ]\n",
    "  pull_request:\n",
    "    branches: [ main ]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "    - uses: actions/checkout@v2\n",
    "    \n",
    "    - name: Set up Python\n",
    "      uses: actions/setup-python@v2\n",
    "      with:\n",
    "        python-version: 3.10\n",
    "    \n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        python -m pip install --upgrade pip\n",
    "        pip install -r api/requirements.txt\n",
    "        pip install pytest pytest-cov\n",
    "    \n",
    "    - name: Run tests\n",
    "      run: |\n",
    "        pytest tests/ -v --cov=api\n",
    "    \n",
    "    - name: Upload coverage reports\n",
    "      uses: codecov/codecov-action@v2\n",
    "  \n",
    "  build:\n",
    "    needs: test\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "    - uses: actions/checkout@v2\n",
    "    \n",
    "    - name: Build Docker image\n",
    "      run: |\n",
    "        docker build -t airparadis-sentiment-api:latest ./api\n",
    "    \n",
    "    - name: Login to Docker Hub\n",
    "      uses: docker/login-action@v1\n",
    "      with:\n",
    "        username: ${{ secrets.DOCKER_USERNAME }}\n",
    "        password: ${{ secrets.DOCKER_PASSWORD }}\n",
    "    \n",
    "    - name: Push Docker image\n",
    "      run: |\n",
    "        docker tag airparadis-sentiment-api:latest ${{ secrets.DOCKER_USERNAME }}/airparadis-sentiment-api:latest\n",
    "        docker push ${{ secrets.DOCKER_USERNAME }}/airparadis-sentiment-api:latest\n",
    "  \n",
    "  deploy:\n",
    "    needs: build\n",
    "    runs-on: ubuntu-latest\n",
    "    if: github.ref == 'refs/heads/main'\n",
    "    \n",
    "    steps:\n",
    "    - name: Deploy to Azure Web App\n",
    "      uses: azure/webapps-deploy@v2\n",
    "      with:\n",
    "        app-name: airparadis-sentiment-api\n",
    "        publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE }}\n",
    "        images: ${{ secrets.DOCKER_USERNAME }}/airparadis-sentiment-api:latest\n",
    "'''\n",
    "\n",
    "print(\"Fichier .github/workflows/deploy.yml :\")\n",
    "print(\"=\"*80)\n",
    "print(workflow_yaml)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Étapes du Pipeline\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────┐\n",
    "│  1. TRIGGER                                                │\n",
    "│     Push sur main ou Pull Request                         │\n",
    "└────────────────────────────────────────────────────────────┘\n",
    "                         ↓\n",
    "┌────────────────────────────────────────────────────────────┐\n",
    "│  2. TEST                                                   │\n",
    "│     - Checkout code                                        │\n",
    "│     - Install Python 3.10                                  │\n",
    "│     - Install dependencies                                 │\n",
    "│     - Run pytest                                           │\n",
    "└────────────────────────────────────────────────────────────┘\n",
    "                         ↓\n",
    "┌────────────────────────────────────────────────────────────┐\n",
    "│  3. BUILD (si tests OK)                                    │\n",
    "│     - Build Docker image                                   │\n",
    "│     - Login to Docker Hub                                  │\n",
    "│     - Push image to registry                               │\n",
    "└────────────────────────────────────────────────────────────┘\n",
    "                         ↓\n",
    "┌────────────────────────────────────────────────────────────┐\n",
    "│  4. DEPLOY (si build OK + branch main)                     │\n",
    "│     - Deploy to Azure Web App                              │\n",
    "│     - Update production environment                        │\n",
    "└────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Captures d'écran à inclure** :\n",
    "- Vue de la liste des workflows GitHub Actions\n",
    "- Détail d'un workflow réussi avec toutes les étapes\n",
    "- Logs de l'exécution des tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Avantages du CI/CD\n",
    "\n",
    "✅ **Automatisation complète** : Plus besoin de déployer manuellement\n",
    "\n",
    "✅ **Qualité garantie** : Déploiement seulement si tous les tests passent\n",
    "\n",
    "✅ **Déploiement rapide** : De quelques minutes au lieu de plusieurs heures\n",
    "\n",
    "✅ **Traçabilité** : Historique complet de tous les déploiements\n",
    "\n",
    "✅ **Rollback facile** : Retour à une version précédente en un clic\n",
    "\n",
    "✅ **Confiance** : Réduction des erreurs humaines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitoring en Production <a id=\"7-monitoring\"></a>\n",
    "\n",
    "### 7.1 Azure Application Insights\n",
    "\n",
    "**Application Insights** permet de monitorer :\n",
    "- Volume de requêtes\n",
    "- Temps de réponse\n",
    "- Taux d'erreur\n",
    "- Traces personnalisées (prédictions non conformes)\n",
    "- Exceptions et logs\n",
    "\n",
    "### 7.2 Configuration dans l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de configuration Application Insights :\n",
      "================================================================================\n",
      "\n",
      "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
      "from opencensus.ext.flask.flask_middleware import FlaskMiddleware\n",
      "from opencensus.ext.azure.trace_exporter import AzureExporter\n",
      "import logging\n",
      "\n",
      "# Configuration du logger\n",
      "logger = logging.getLogger(__name__)\n",
      "logger.addHandler(AzureLogHandler(\n",
      "    connection_string='InstrumentationKey=YOUR_KEY'\n",
      "))\n",
      "\n",
      "# Ajouter le middleware Flask\n",
      "middleware = FlaskMiddleware(\n",
      "    app,\n",
      "    exporter=AzureExporter(\n",
      "        connection_string='InstrumentationKey=YOUR_KEY'\n",
      "    ),\n",
      "    sampler=ProbabilitySampler(rate=1.0)\n",
      ")\n",
      "\n",
      "# Dans le endpoint de prédiction\n",
      "@app.route('/predict', methods=['POST'])\n",
      "def predict():\n",
      "    data = request.get_json()\n",
      "    text = data.get('text')\n",
      "    \n",
      "    # Prédiction\n",
      "    prediction = model.predict([text])[0]\n",
      "    proba = model.predict_proba([text])[0][prediction]\n",
      "    \n",
      "    # Logger la prédiction\n",
      "    logger.info(f\"Prediction made: {prediction}, confidence: {proba:.2f}\")\n",
      "    \n",
      "    # Si prédiction non conforme (faible confiance)\n",
      "    if proba < 0.6:\n",
      "        logger.warning(\n",
      "            f\"Low confidence prediction: {proba:.2f} for text: {text[:50]}\",\n",
      "            extra={'custom_dimensions': {\n",
      "                'prediction': int(prediction),\n",
      "                'confidence': float(proba),\n",
      "                'text_length': len(text)\n",
      "            }}\n",
      "        )\n",
      "    \n",
      "    return jsonify({\n",
      "        'sentiment': int(prediction),\n",
      "        'proba': float(proba)\n",
      "    })\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exemple de configuration Application Insights dans Flask\n",
    "app_insights_code = '''\n",
    "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
    "from opencensus.ext.flask.flask_middleware import FlaskMiddleware\n",
    "from opencensus.ext.azure.trace_exporter import AzureExporter\n",
    "import logging\n",
    "\n",
    "# Configuration du logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(AzureLogHandler(\n",
    "    connection_string='InstrumentationKey=YOUR_KEY'\n",
    "))\n",
    "\n",
    "# Ajouter le middleware Flask\n",
    "middleware = FlaskMiddleware(\n",
    "    app,\n",
    "    exporter=AzureExporter(\n",
    "        connection_string='InstrumentationKey=YOUR_KEY'\n",
    "    ),\n",
    "    sampler=ProbabilitySampler(rate=1.0)\n",
    ")\n",
    "\n",
    "# Dans le endpoint de prédiction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    text = data.get('text')\n",
    "    \n",
    "    # Prédiction\n",
    "    prediction = model.predict([text])[0]\n",
    "    proba = model.predict_proba([text])[0][prediction]\n",
    "    \n",
    "    # Logger la prédiction\n",
    "    logger.info(f\"Prediction made: {prediction}, confidence: {proba:.2f}\")\n",
    "    \n",
    "    # Si prédiction non conforme (faible confiance)\n",
    "    if proba < 0.6:\n",
    "        logger.warning(\n",
    "            f\"Low confidence prediction: {proba:.2f} for text: {text[:50]}\",\n",
    "            extra={'custom_dimensions': {\n",
    "                'prediction': int(prediction),\n",
    "                'confidence': float(proba),\n",
    "                'text_length': len(text)\n",
    "            }}\n",
    "        )\n",
    "    \n",
    "    return jsonify({\n",
    "        'sentiment': int(prediction),\n",
    "        'proba': float(proba)\n",
    "    })\n",
    "'''\n",
    "\n",
    "print(\"Exemple de configuration Application Insights :\")\n",
    "print(\"=\"*80)\n",
    "print(app_insights_code)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Alertes Configurées\n",
    "\n",
    "Nous avons configuré plusieurs alertes dans Azure :\n",
    "\n",
    "**1. Alerte de latence élevée**\n",
    "- Condition : Temps de réponse > 500ms pendant 5 minutes\n",
    "- Action : Email à l'équipe DevOps\n",
    "\n",
    "**2. Alerte de taux d'erreur élevé**\n",
    "- Condition : Erreurs > 5% des requêtes pendant 10 minutes\n",
    "- Action : Email + SMS aux responsables\n",
    "\n",
    "**3. Alerte de prédictions non conformes**\n",
    "- Condition : > 20% de prédictions avec confiance < 60%\n",
    "- Action : Email au Data Science team (re-training nécessaire)\n",
    "\n",
    "**4. Alerte de volume anormal**\n",
    "- Condition : Volume < 10 req/min (possible downtime)\n",
    "- Action : SMS immédiat\n",
    "\n",
    "### 7.4 Dashboard de Monitoring\n",
    "\n",
    "**Captures d'écran à inclure** :\n",
    "- Dashboard Application Insights avec graphiques de métriques\n",
    "- Exemple de trace d'une prédiction non conforme\n",
    "- Configuration d'une alerte\n",
    "- Email/SMS d'alerte reçu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Stratégie de Maintenance du Modèle\n",
    "\n",
    "#### Analyse de la Stabilité dans le Temps\n",
    "\n",
    "**Indicateurs à surveiller** :\n",
    "1. **Taux de prédictions non conformes** (confiance < 60%)\n",
    "2. **Distribution des sentiments** (changement de ratio positif/négatif)\n",
    "3. **Feedback utilisateurs** (corrections manuelles)\n",
    "4. **Nouveaux mots/hashtags** non vus pendant l'entraînement\n",
    "\n",
    "#### Actions d'Amélioration\n",
    "\n",
    "**Court terme** (hebdomadaire) :\n",
    "- Analyser les prédictions corrigées par les utilisateurs\n",
    "- Identifier les patterns d'erreurs\n",
    "- Enrichir le dataset avec ces exemples\n",
    "\n",
    "**Moyen terme** (mensuel) :\n",
    "- Re-entraîner le modèle avec nouvelles données\n",
    "- Comparer performances ancien vs nouveau modèle\n",
    "- Déployer si amélioration significative (> 2% F1-Score)\n",
    "\n",
    "**Long terme** (trimestriel) :\n",
    "- Analyser l'évolution du vocabulaire Twitter\n",
    "- Tester de nouvelles architectures (nouveaux modèles BERT, etc.)\n",
    "- Optimiser les hyperparamètres\n",
    "- Évaluer le ROI du modèle (détections de bad buzz réussies)\n",
    "\n",
    "#### Critères de Re-training\n",
    "\n",
    "Déclencher un re-training si :\n",
    "- ✅ > 1000 nouvelles corrections utilisateurs collectées\n",
    "- ✅ Taux de prédictions non conformes > 25% (vs 15% initial)\n",
    "- ✅ Changement significatif dans la distribution des données\n",
    "- ✅ Nouveau vocabulaire détecté (nouveaux hashtags, événements)\n",
    "\n",
    "#### Workflow de Re-training Automatisé\n",
    "\n",
    "```\n",
    "1. Collecte automatique des feedbacks (Streamlit → Database)\n",
    "2. Détection de drift (monitoring Azure)\n",
    "3. Trigger re-training (GitHub Actions scheduled workflow)\n",
    "4. Entraînement et évaluation (MLFlow tracking)\n",
    "5. Validation sur test set hold-out\n",
    "6. Si amélioration > seuil → Deploy en Staging\n",
    "7. A/B Testing Staging vs Production (1 semaine)\n",
    "8. Si OK → Promote en Production\n",
    "9. Ancien modèle → Archive dans MLFlow Registry\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion <a id=\"8-conclusion\"></a>\n",
    "\n",
    "### Récapitulatif de la Démarche MLOps\n",
    "\n",
    "Ce projet a mis en œuvre une démarche MLOps complète :\n",
    "\n",
    "✅ **Tracking des expérimentations** : MLFlow pour suivre tous les runs\n",
    "\n",
    "✅ **Stockage centralisé** : MLFlow Model Registry pour versionner les modèles\n",
    "\n",
    "✅ **Versioning du code** : Git/GitHub avec historique complet\n",
    "\n",
    "✅ **Tests automatisés** : pytest pour garantir la qualité\n",
    "\n",
    "✅ **CI/CD** : GitHub Actions pour déploiement automatique\n",
    "\n",
    "✅ **Monitoring** : Azure Application Insights pour surveillance production\n",
    "\n",
    "✅ **Alertes** : Notifications en cas de problème\n",
    "\n",
    "✅ **Stratégie de maintenance** : Plan de re-training et amélioration continue\n",
    "\n",
    "### Bénéfices pour Air Paradis\n",
    "\n",
    "**Qualité** :\n",
    "- Tests automatisés → Moins de bugs\n",
    "- Validation systématique avant déploiement\n",
    "\n",
    "**Rapidité** :\n",
    "- Déploiement en minutes (vs heures/jours)\n",
    "- Itérations rapides avec feedback utilisateurs\n",
    "\n",
    "**Fiabilité** :\n",
    "- Monitoring 24/7 → Détection rapide des problèmes\n",
    "- Rollback facile en cas d'incident\n",
    "\n",
    "**Évolutivité** :\n",
    "- Infrastructure Cloud scalable automatiquement\n",
    "- Prêt pour croissance du volume de données\n",
    "\n",
    "**Traçabilité** :\n",
    "- Historique complet de tous les modèles\n",
    "- Reproductibilité garantie\n",
    "\n",
    "### Prochaines Étapes\n",
    "\n",
    "1. **Enrichissement du dataset** avec tweets spécifiques Air Paradis\n",
    "2. **A/B Testing** pour comparer modèles en production\n",
    "3. **Optimisation des coûts** Cloud (caching, batching)\n",
    "4. **Features avancées** : détection de sarcasme, analyse des émotions\n",
    "5. **Dashboard métier** pour équipes marketing\n",
    "\n",
    "---\n",
    "\n",
    "**Ce notebook a démontré une mise en œuvre complète et professionnelle des pratiques MLOps, conformément aux exigences du projet.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
