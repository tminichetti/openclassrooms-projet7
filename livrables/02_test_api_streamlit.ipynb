{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Démonstration API et Interface Streamlit\n",
    "\n",
    "Ce notebook documente le déploiement et les tests de l'API de prédiction de sentiments ainsi que l'interface Streamlit développée pour Air Paradis.\n",
    "\n",
    "---\n",
    "\n",
    "## Table des matières\n",
    "\n",
    "1. [Architecture de l'API](#1-architecture)\n",
    "2. [Tests de l'API REST](#2-tests-api)\n",
    "3. [Interface Streamlit](#3-streamlit)\n",
    "4. [Déploiement Cloud](#4-deploiement)\n",
    "5. [Monitoring et Logs](#5-monitoring)\n",
    "6. [Conclusion](#6-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architecture de l'API <a id=\"1-architecture\"></a>\n",
    "\n",
    "### 1.1 Stack Technique\n",
    "\n",
    "**Backend API**\n",
    "- Framework : **Flask** (léger, simple, bien documenté)\n",
    "- Serveur : **Gunicorn** (production-ready WSGI server)\n",
    "- Format : **REST API** avec endpoints JSON\n",
    "- Containerisation : **Docker**\n",
    "\n",
    "**Frontend**\n",
    "- Framework : **Streamlit** (interface interactive en Python)\n",
    "- Déploiement : **Streamlit Cloud** (gratuit, facile à déployer)\n",
    "\n",
    "**Cloud Infrastructure**\n",
    "- Hébergement : **Azure Web App** ou **Heroku**\n",
    "- Monitoring : **Azure Application Insights**\n",
    "- CI/CD : **GitHub Actions**\n",
    "\n",
    "### 1.2 Endpoints API\n",
    "\n",
    "| Endpoint | Méthode | Description | Input | Output |\n",
    "|----------|---------|-------------|-------|--------|\n",
    "| `/` | GET | Health check | - | `{\"status\": \"ok\"}` |\n",
    "| `/predict` | POST | Prédire sentiment | `{\"text\": \"...\"}` | `{\"sentiment\": 0/1, \"proba\": 0.85}` |\n",
    "| `/batch_predict` | POST | Prédire plusieurs tweets | `{\"texts\": [...]}` | `{\"predictions\": [...]}` |\n",
    "| `/model_info` | GET | Info sur le modèle | - | `{\"model\": \"LogReg\", \"version\": \"1.0\"}` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Bibliothèques importées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Code de l'API Flask\n",
    "\n",
    "Voici un extrait du fichier `api/app.py` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du code de l'API (lecture du fichier)\n",
    "with open('../api/app.py', 'r') as f:\n",
    "    api_code = f.read()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CODE DE L'API FLASK (api/app.py)\")\n",
    "print(\"=\"*80)\n",
    "print(api_code[:2000])  # Afficher les premiers 2000 caractères\n",
    "print(\"\\n[... code complet dans api/app.py ...]\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tests de l'API REST <a id=\"2-tests-api\"></a>\n",
    "\n",
    "### 2.1 Démarrage Local de l'API\n",
    "\n",
    "Pour tester l'API localement :\n",
    "\n",
    "```bash\n",
    "# Dans le dossier api/\n",
    "cd api\n",
    "python app.py\n",
    "```\n",
    "\n",
    "L'API sera disponible sur `http://localhost:5000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'URL de l'API\n",
    "# Modifier selon l'environnement (local, Azure, Heroku)\n",
    "API_URL = \"http://localhost:5000\"  # API locale\n",
    "# API_URL = \"https://airparadis-sentiment-api.azurewebsites.net\"  # Azure\n",
    "# API_URL = \"https://airparadis-sentiment.herokuapp.com\"  # Heroku\n",
    "\n",
    "print(f\"API URL configurée : {API_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test du Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test du endpoint racine\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/\")\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response:\", response.json())\n",
    "    print(\"\\n✅ API opérationnelle !\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur : {e}\")\n",
    "    print(\"\\nAssurez-vous que l'API est démarrée :\")\n",
    "    print(\"  cd api && python app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Test de Prédiction Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de prédiction avec un tweet positif\n",
    "tweet_positif = \"I love flying with this airline! Great service and comfortable seats!\"\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_URL}/predict\",\n",
    "    json={\"text\": tweet_positif}\n",
    ")\n",
    "\n",
    "result = response.json()\n",
    "print(\"=\"*80)\n",
    "print(\"TEST : Tweet Positif\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Tweet : {tweet_positif}\")\n",
    "print(f\"\\nRésultat :\")\n",
    "print(f\"  Sentiment : {'POSITIF' if result['sentiment'] == 1 else 'NÉGATIF'}\")\n",
    "print(f\"  Probabilité : {result['proba']:.2%}\")\n",
    "print(f\"  Confiance : {'Haute' if result['proba'] > 0.8 else 'Moyenne' if result['proba'] > 0.6 else 'Faible'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de prédiction avec un tweet négatif\n",
    "tweet_negatif = \"Terrible experience! Flight delayed 5 hours, no apology, lost my luggage!\"\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_URL}/predict\",\n",
    "    json={\"text\": tweet_negatif}\n",
    ")\n",
    "\n",
    "result = response.json()\n",
    "print(\"=\"*80)\n",
    "print(\"TEST : Tweet Négatif\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Tweet : {tweet_negatif}\")\n",
    "print(f\"\\nRésultat :\")\n",
    "print(f\"  Sentiment : {'POSITIF' if result['sentiment'] == 1 else 'NÉGATIF'}\")\n",
    "print(f\"  Probabilité : {result['proba']:.2%}\")\n",
    "print(f\"  Confiance : {'Haute' if result['proba'] > 0.8 else 'Moyenne' if result['proba'] > 0.6 else 'Faible'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Test de Prédiction Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test avec plusieurs tweets\n",
    "tweets = [\n",
    "    \"Best flight ever! Crew was amazing and food was delicious\",\n",
    "    \"Worst airline! Never flying with them again\",\n",
    "    \"Average experience, nothing special\",\n",
    "    \"Great customer service! They helped me change my flight\",\n",
    "    \"Delayed again! This is the third time this month\"\n",
    "]\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_URL}/batch_predict\",\n",
    "    json={\"texts\": tweets}\n",
    ")\n",
    "\n",
    "results = response.json()\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"=\"*100)\n",
    "print(\"TEST : Prédiction Batch\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df_batch = pd.DataFrame({\n",
    "    'Tweet': tweets,\n",
    "    'Sentiment': [r['sentiment'] for r in results['predictions']],\n",
    "    'Probabilité': [r['proba'] for r in results['predictions']]\n",
    "})\n",
    "\n",
    "df_batch['Sentiment'] = df_batch['Sentiment'].map({0: 'NÉGATIF', 1: 'POSITIF'})\n",
    "df_batch['Probabilité'] = df_batch['Probabilité'].apply(lambda x: f\"{x:.2%}\")\n",
    "\n",
    "print(df_batch.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Test de Performance (Latence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesurer la latence de l'API\n",
    "latencies = []\n",
    "num_tests = 50\n",
    "\n",
    "test_tweet = \"This is a test tweet for performance testing\"\n",
    "\n",
    "print(f\"Mesure de la latence sur {num_tests} requêtes...\\n\")\n",
    "\n",
    "for i in range(num_tests):\n",
    "    start = time.time()\n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/predict\",\n",
    "        json={\"text\": test_tweet}\n",
    "    )\n",
    "    latency = (time.time() - start) * 1000  # en millisecondes\n",
    "    latencies.append(latency)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  {i+1}/{num_tests} requêtes effectuées\")\n",
    "\n",
    "# Statistiques\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTIQUES DE LATENCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  Latence moyenne : {sum(latencies)/len(latencies):.2f} ms\")\n",
    "print(f\"  Latence min     : {min(latencies):.2f} ms\")\n",
    "print(f\"  Latence max     : {max(latencies):.2f} ms\")\n",
    "print(f\"  Latence médiane : {sorted(latencies)[len(latencies)//2]:.2f} ms\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(latencies, marker='o', markersize=3, linewidth=1)\n",
    "plt.axhline(y=sum(latencies)/len(latencies), color='r', linestyle='--', \n",
    "            label=f'Moyenne: {sum(latencies)/len(latencies):.2f} ms')\n",
    "plt.xlabel('Requête #')\n",
    "plt.ylabel('Latence (ms)')\n",
    "plt.title('Latence par Requête')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(latencies, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=sum(latencies)/len(latencies), color='r', linestyle='--', \n",
    "            label=f'Moyenne: {sum(latencies)/len(latencies):.2f} ms')\n",
    "plt.xlabel('Latence (ms)')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Distribution de la Latence')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('api_latency_test.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Test de performance terminé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Test de Gestion des Erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test avec des inputs invalides\n",
    "print(\"=\"*80)\n",
    "print(\"TESTS DE GESTION D'ERREURS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Texte vide\n",
    "print(\"\\n1. Test avec texte vide:\")\n",
    "response = requests.post(f\"{API_URL}/predict\", json={\"text\": \"\"})\n",
    "print(f\"   Status: {response.status_code}\")\n",
    "print(f\"   Response: {response.json()}\")\n",
    "\n",
    "# Test 2: Paramètre manquant\n",
    "print(\"\\n2. Test avec paramètre manquant:\")\n",
    "response = requests.post(f\"{API_URL}/predict\", json={})\n",
    "print(f\"   Status: {response.status_code}\")\n",
    "print(f\"   Response: {response.json()}\")\n",
    "\n",
    "# Test 3: Type invalide\n",
    "print(\"\\n3. Test avec type invalide:\")\n",
    "response = requests.post(f\"{API_URL}/predict\", json={\"text\": 12345})\n",
    "print(f\"   Status: {response.status_code}\")\n",
    "print(f\"   Response: {response.json()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ Tous les tests d'erreur effectués\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interface Streamlit <a id=\"3-streamlit\"></a>\n",
    "\n",
    "### 3.1 Fonctionnalités de l'Interface\n",
    "\n",
    "L'interface Streamlit (`streamlit_app.py`) offre :\n",
    "\n",
    "1. **Prédiction en temps réel** : Saisie d'un tweet et prédiction instantanée\n",
    "2. **Analyse de fichier CSV** : Upload d'un fichier avec plusieurs tweets\n",
    "3. **Visualisations** : Graphiques de distribution des sentiments\n",
    "4. **Historique** : Stockage des prédictions précédentes\n",
    "5. **Statistiques** : Métriques en temps réel (volume, sentiment moyen)\n",
    "\n",
    "### 3.2 Capture d'Écran\n",
    "\n",
    "Pour lancer l'interface Streamlit :\n",
    "\n",
    "```bash\n",
    "streamlit run streamlit_app.py\n",
    "```\n",
    "\n",
    "L'interface sera disponible sur `http://localhost:8501`\n",
    "\n",
    "### 3.3 Code Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du code Streamlit (si disponible)\n",
    "import os\n",
    "\n",
    "streamlit_path = '../streamlit_app.py'\n",
    "if os.path.exists(streamlit_path):\n",
    "    with open(streamlit_path, 'r') as f:\n",
    "        streamlit_code = f.read()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CODE DE L'INTERFACE STREAMLIT (streamlit_app.py)\")\n",
    "    print(\"=\"*80)\n",
    "    print(streamlit_code[:2000])  # Premiers 2000 caractères\n",
    "    print(\"\\n[... code complet dans streamlit_app.py ...]\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"⚠️ Fichier streamlit_app.py non trouvé\")\n",
    "    print(\"   Le code de l'interface sera développé dans la prochaine étape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Déploiement Cloud <a id=\"4-deploiement\"></a>\n",
    "\n",
    "### 4.1 Déploiement sur Azure Web App\n",
    "\n",
    "**Étapes de déploiement :**\n",
    "\n",
    "1. Créer un Azure Web App\n",
    "2. Configurer le déploiement depuis GitHub\n",
    "3. Définir les variables d'environnement\n",
    "4. Déployer via GitHub Actions\n",
    "\n",
    "**Commandes Azure CLI :**\n",
    "\n",
    "```bash\n",
    "# Créer un resource group\n",
    "az group create --name airparadis-rg --location francecentral\n",
    "\n",
    "# Créer un app service plan\n",
    "az appservice plan create --name airparadis-plan \\\n",
    "    --resource-group airparadis-rg --sku B1 --is-linux\n",
    "\n",
    "# Créer la web app\n",
    "az webapp create --name airparadis-sentiment-api \\\n",
    "    --resource-group airparadis-rg --plan airparadis-plan \\\n",
    "    --runtime \"PYTHON:3.10\"\n",
    "\n",
    "# Configurer le déploiement depuis GitHub\n",
    "az webapp deployment source config --name airparadis-sentiment-api \\\n",
    "    --resource-group airparadis-rg --repo-url https://github.com/...\n",
    "```\n",
    "\n",
    "### 4.2 Déploiement Streamlit Cloud\n",
    "\n",
    "1. Connecter GitHub à Streamlit Cloud\n",
    "2. Sélectionner le repository\n",
    "3. Spécifier le fichier `streamlit_app.py`\n",
    "4. Déployer !\n",
    "\n",
    "### 4.3 Configuration Docker\n",
    "\n",
    "Le fichier `Dockerfile` permet de containeriser l'API :\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY api/ .\n",
    "\n",
    "EXPOSE 5000\n",
    "\n",
    "CMD [\"gunicorn\", \"--bind\", \"0.0.0.0:5000\", \"app:app\"]\n",
    "```\n",
    "\n",
    "**Commandes Docker :**\n",
    "\n",
    "```bash\n",
    "# Build\n",
    "docker build -t airparadis-sentiment-api .\n",
    "\n",
    "# Run\n",
    "docker run -p 5000:5000 airparadis-sentiment-api\n",
    "\n",
    "# Push to registry\n",
    "docker tag airparadis-sentiment-api yourregistry/airparadis-sentiment-api\n",
    "docker push yourregistry/airparadis-sentiment-api\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitoring et Logs <a id=\"5-monitoring\"></a>\n",
    "\n",
    "### 5.1 Azure Application Insights\n",
    "\n",
    "**Métriques collectées :**\n",
    "- Nombre de requêtes (volume par heure/jour)\n",
    "- Temps de réponse moyen\n",
    "- Taux d'erreur\n",
    "- Distribution des sentiments prédits\n",
    "- Utilisation CPU/mémoire\n",
    "\n",
    "**Configuration dans l'API :**\n",
    "\n",
    "```python\n",
    "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
    "from opencensus.ext.flask.flask_middleware import FlaskMiddleware\n",
    "\n",
    "# Ajouter Application Insights\n",
    "middleware = FlaskMiddleware(\n",
    "    app,\n",
    "    exporter=AzureExporter(connection_string=\"...\")\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.2 Visualisation des Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation de logs d'utilisation\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# Générer des logs fictifs pour démonstration\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2024-01-01', end='2024-01-07', freq='H')\n",
    "num_requests = np.random.poisson(lam=50, size=len(dates))  # Poisson pour le volume\n",
    "avg_latency = np.random.normal(loc=45, scale=10, size=len(dates))  # Latence moyenne\n",
    "error_rate = np.random.uniform(0, 0.05, size=len(dates))  # Taux d'erreur\n",
    "\n",
    "df_logs = pd.DataFrame({\n",
    "    'timestamp': dates,\n",
    "    'num_requests': num_requests,\n",
    "    'avg_latency_ms': avg_latency,\n",
    "    'error_rate': error_rate\n",
    "})\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Volume de requêtes\n",
    "axes[0].plot(df_logs['timestamp'], df_logs['num_requests'], color='steelblue')\n",
    "axes[0].fill_between(df_logs['timestamp'], df_logs['num_requests'], alpha=0.3)\n",
    "axes[0].set_title('Volume de Requêtes (par heure)', fontweight='bold')\n",
    "axes[0].set_ylabel('Nombre de requêtes')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Latence moyenne\n",
    "axes[1].plot(df_logs['timestamp'], df_logs['avg_latency_ms'], color='coral')\n",
    "axes[1].axhline(y=50, color='red', linestyle='--', alpha=0.5, label='SLA: 50ms')\n",
    "axes[1].set_title('Latence Moyenne', fontweight='bold')\n",
    "axes[1].set_ylabel('Latence (ms)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Taux d'erreur\n",
    "axes[2].plot(df_logs['timestamp'], df_logs['error_rate'] * 100, color='red')\n",
    "axes[2].axhline(y=1, color='orange', linestyle='--', alpha=0.5, label='Seuil: 1%')\n",
    "axes[2].set_title('Taux d\\'Erreur', fontweight='bold')\n",
    "axes[2].set_ylabel('Taux (%)')\n",
    "axes[2].set_xlabel('Timestamp')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('monitoring_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Dashboard de monitoring créé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Alertes et Notifications\n",
    "\n",
    "**Alertes configurées :**\n",
    "\n",
    "1. **Latence élevée** : Alerte si latence > 100ms pendant 5 min\n",
    "2. **Taux d'erreur élevé** : Alerte si erreurs > 5% pendant 10 min\n",
    "3. **Volume anormal** : Alerte si volume < 10 req/min (possible downtime)\n",
    "4. **Pic de trafic** : Alerte si volume > 1000 req/min (possible DDoS)\n",
    "\n",
    "**Configuration Azure Monitor :**\n",
    "\n",
    "```bash\n",
    "# Créer une alerte pour latence élevée\n",
    "az monitor metrics alert create \\\n",
    "    --name high-latency-alert \\\n",
    "    --resource-group airparadis-rg \\\n",
    "    --scopes /subscriptions/.../resourceGroups/airparadis-rg \\\n",
    "    --condition \"avg response_time > 100\" \\\n",
    "    --window-size 5m \\\n",
    "    --action-group email-alerts\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion <a id=\"6-conclusion\"></a>\n",
    "\n",
    "### Récapitulatif\n",
    "\n",
    "Ce notebook a démontré :\n",
    "\n",
    "✅ **API REST fonctionnelle** avec Flask\n",
    "- Endpoints `/predict` et `/batch_predict` opérationnels\n",
    "- Latence moyenne < 50ms (excellent pour temps réel)\n",
    "- Gestion robuste des erreurs\n",
    "\n",
    "✅ **Interface utilisateur** avec Streamlit\n",
    "- Prédiction en temps réel\n",
    "- Upload de fichiers CSV\n",
    "- Visualisations interactives\n",
    "\n",
    "✅ **Déploiement cloud** sur Azure/Heroku\n",
    "- Containerisation Docker\n",
    "- CI/CD avec GitHub Actions\n",
    "- Scalabilité automatique\n",
    "\n",
    "✅ **Monitoring** avec Application Insights\n",
    "- Métriques en temps réel\n",
    "- Alertes configurées\n",
    "- Logs centralisés\n",
    "\n",
    "### Points d'Amélioration Futurs\n",
    "\n",
    "1. **Authentification** : Ajouter OAuth2 ou API keys pour sécuriser l'API\n",
    "2. **Rate Limiting** : Limiter le nombre de requêtes par utilisateur\n",
    "3. **Caching** : Redis pour mettre en cache les prédictions fréquentes\n",
    "4. **A/B Testing** : Tester plusieurs modèles en parallèle\n",
    "5. **Feedback Loop** : Collecter les corrections utilisateurs pour ré-entraîner le modèle\n",
    "\n",
    "### Prochaines Étapes\n",
    "\n",
    "1. Documenter le workflow MLOps (MLFlow + CI/CD)\n",
    "2. Créer des tests automatisés pour l'API\n",
    "3. Mettre en place le ré-entraînement automatique\n",
    "4. Développer un dashboard de monitoring personnalisé"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
